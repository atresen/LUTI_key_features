{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "os.mkdir(\"uorfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to find ATGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### function\n",
    "\n",
    "def getuORFS(bedfile, fastafile, outfile):\n",
    "    ### convert bed file to dataframe\n",
    "    bed = pd.read_csv(bedfile, sep='\\t', header=None)\n",
    "\n",
    "    ### take input bedfile and make a new fasta with specified sequences\n",
    "    cmd = \"bedtools getfasta -s -fi \"+fastafile+\" -bed \"+bedfile+\" -fo uorfs/\" + outfile + \"_codoncount.fasta\"\n",
    "    os.system(cmd)\n",
    "    newfasta = open(\"uorfs/\" + outfile + \"_codoncount.fasta\")\n",
    "\n",
    "    ### to return ATG starts:\n",
    "    codons = [\"ATG\"]\n",
    "    \n",
    "    ### create list with the number of uORFs for each sequence line in the fasta file \n",
    "    uorf_number = []\n",
    "    length = []\n",
    "    positions = []\n",
    "    ### create list that will contain the uORF number matched to the systemmatic gene name\n",
    "    todf = []\n",
    "\n",
    "    for idx,line in enumerate(newfasta):\n",
    "        for codon in codons:\n",
    "            if line[0]!=\">\":\n",
    "                position = [m.start() for m in re.finditer(codon,line)]\n",
    "                positions.append(position)\n",
    "                uorf_number.append(len(position))\n",
    "                length.append(len(line))\n",
    "                todf.append(bed.iloc[int((idx/2)), 3] + '\\t' + str(uorf_number[int(idx/2)]) + '\\t' + str(positions[int(idx/2)]))\n",
    "\n",
    "\n",
    "    series = pd.Series(todf)\n",
    "    df = pd.DataFrame(series)\n",
    "    df['parent'], df['uorf_number'], df['positions'] = df[0].str.split('\\t', 2).str\n",
    "    df['positions'] = df['positions'].str.strip(\"[\").str.strip(\"]\")\n",
    "    series2 = pd.Series(length)\n",
    "    df['length'] = series2\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "    df['rate'] = df['uorf_number'].astype('float') / (df['length'].astype('float')/3)\n",
    "    print('ATG per codon: ' + str(df['rate'].mean()))\n",
    "    df.to_csv('uorfs/' + outfile + '.txt', sep='\\t', index=None)\n",
    "    os.remove(\"uorfs/\" + outfile + \"_codoncount.fasta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply function to specified regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATG per codon: 0.04879722205421276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### get the uORF count between orf and luti TSSs, the distance, and the rate at each locus\n",
    "\n",
    "bedfile = 'bedfiles/181130TSS_between_prox_and_luti.bed'\n",
    "fastafile = 'genome_files/SK1_PacBio_spikes.genome.fa'\n",
    "outfile = 'ATGs_between_prox_and_luti'\n",
    "\n",
    "getuORFS(bedfile, fastafile, outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATG per codon: 0.05057374455284471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### get the uORFs in the 500 bp upstream of all genes without LUTIs\n",
    "\n",
    "bedfile = 'bedfiles/nonlutiup500.bed'\n",
    "fastafile = 'genome_files/SK1_PacBio_spikes.genome.fa'\n",
    "outfile = 'uorfs_nonluti_up500'\n",
    "\n",
    "getuORFS(bedfile, fastafile, outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To find the positions of the uORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bring in the ATG positions relative to the LUTI TSS\n",
    "\n",
    "pos = pd.read_csv('uorfs/ATGs_between_prox_and_luti.txt', sep='\\t')\n",
    "\n",
    "# convert the string of locations to a list\n",
    "pos['positions'] = pos['positions'].astype(str).map(lambda x: x.replace('[', '').replace(']', '').replace(',', ''))\n",
    "\n",
    "pos['positions'] = pos['positions'].str.split(' ')\n",
    "\n",
    "# give each entry in each list its own row\n",
    "lists = pos.apply(lambda x: pd.Series(x['positions']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "\n",
    "lists.name = 'position'\n",
    "\n",
    "pos = pos.drop('positions', axis=1).join(lists)\n",
    "\n",
    "\n",
    "\n",
    "# bring in the LUTI TSS chromosome coordinates to get the chromosome positions of each ATG\n",
    "\n",
    "tss = pd.read_csv('bedfiles/181130TSS_between_prox_and_luti.bed', sep='\\t', header=None)\n",
    "\n",
    "pos = pos.merge(tss, how='left', left_on='parent', right_on=3)\n",
    "\n",
    "pos = pos[~((pos['position'] == 'nan') | (pos['position'] == '0'))]\n",
    "\n",
    "pos['count'] = pos.groupby('parent').cumcount()+1\n",
    "\n",
    "pos['parent'] = pos['parent'] + '_' + pos['count'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expand the bases to include the region around the ATG\n",
    "\n",
    "def expand(numcodon, df):\n",
    "    plus_mask = (pos[5] == '+')\n",
    "    minus_mask = (pos[5] == '-')\n",
    "    \n",
    "    df['start'] = pos[1]\n",
    "    df['stop'] = pos[2]\n",
    "    df.loc[plus_mask, 'start'] += df.loc[plus_mask, 'position'].astype(int)\n",
    "    df.loc[plus_mask, 'stop'] = df.loc[plus_mask, 'start']\n",
    "    df.loc[plus_mask, 'stop'] += (3 * numcodon)\n",
    "\n",
    "    df.loc[minus_mask, 'stop'] -= df.loc[minus_mask, 'position'].astype(int)\n",
    "    df.loc[minus_mask, 'start'] = df.loc[minus_mask, 'stop']\n",
    "    df.loc[minus_mask, 'start'] -= (3 * numcodon) \n",
    "\n",
    "    bed = pd.DataFrame()\n",
    "    bed[0] = pos[0]\n",
    "    bed[1] = pos[1] - (3 * numcodon)\n",
    "    bed[2] = pos[2] + (3 * numcodon)\n",
    "    bed[3] = pos['parent']\n",
    "    bed[4] = pos[4]\n",
    "    bed[5] = pos[5]\n",
    "    bed[6] = pos['start']\n",
    "    bed[7] = pos['stop']\n",
    "\n",
    "    bed.to_csv('uorfs/atgpositions' + '_' + str(numcodon) + 'codons.bed', sep='\\t', header=None, index=None)\n",
    "    \n",
    "\n",
    "# run for the 6 codons including and downstream of the ATG\n",
    "\n",
    "expand(6, pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ran fp-count from the Ingolia lab's Riboseq code (https://github.com/ingolia-lab/RiboSeq) \n",
    "# using the 6 codon version of the bed file produced above\n",
    "\n",
    "fpcounts = pd.read_csv('uorfs/3h_fp_vs_genome_unique_qexpr_6codons.txt', \n",
    "                       sep='\\t', header=None)\n",
    "\n",
    "fpcounts['parent'] = fpcounts[0].str.split('_', expand=True)[0]\n",
    "fpcounts['uORF number'] = fpcounts[0].str.split('_', expand=True)[1]\n",
    "fpcounts['uORF number'] = fpcounts['uORF number'].astype(int)\n",
    "fpcounts['count'] = fpcounts[2]\n",
    "fpcounts['enriched'] = fpcounts['count'] > 3\n",
    "\n",
    "fpcounts.set_index('parent', inplace=True)\n",
    "\n",
    "\n",
    "fpg = (fpcounts.groupby(level='parent', group_keys=False)\n",
    "       .filter(lambda x: len(x) > 3))\n",
    "\n",
    "\n",
    "fpg = fpg.groupby(level='parent', group_keys=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to get the percent translated\n",
    "\n",
    "first = fpg.nth(0)\n",
    "second = fpg.nth(1)\n",
    "slast = fpg.nth(-2)\n",
    "last = fpg.nth(-1)\n",
    "\n",
    "dfs = [first, second, slast, last]\n",
    "uorfpos = ['First', 'Second', 'Penultimate', 'Last']\n",
    "\n",
    "def pcttrue(df):\n",
    "    pcttrue = df['enriched'].value_counts(normalize=True) * 100\n",
    "    return pcttrue\n",
    "    \n",
    "lst = []\n",
    "\n",
    "for idx, i in enumerate(dfs):\n",
    "    lst.append((uorfpos[idx],pcttrue(i)[1]))\n",
    "\n",
    "# add the first two in combination and the last two in combination\n",
    "fs = first.merge(second, how='inner', on='parent', suffixes=['_first', '_second'])\n",
    "fs = fs[(fs['enriched_first'] == True) & (fs['enriched_second'] == True)] \n",
    "lst.insert(2, ('First Two', len(fs)/len(first)*100))       \n",
    "                \n",
    "pl = last.merge(slast, how='inner', on='parent', suffixes=['_last', '_slast'])\n",
    "pl = pl[(pl['enriched_last'] == True) & (pl['enriched_slast'] == True)] \n",
    "lst.insert(5, ('Last Two', len(pl)/len(first)*100))       \n",
    "\n",
    "\n",
    "df = pd.DataFrame(lst, columns=['uorfpos', 'pct'])\n",
    "\n",
    "df.to_csv('uorfs/percenttranslated.txt', sep='\\t', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uorfpos</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>78.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second</td>\n",
       "      <td>78.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Two</td>\n",
       "      <td>68.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penultimate</td>\n",
       "      <td>9.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last</td>\n",
       "      <td>20.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Last Two</td>\n",
       "      <td>4.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uorfpos      pct\n",
       "0        First  78.1250\n",
       "1       Second  78.1250\n",
       "2    First Two  68.7500\n",
       "3  Penultimate   9.3750\n",
       "4         Last  20.3125\n",
       "5     Last Two   4.6875"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
